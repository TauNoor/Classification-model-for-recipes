{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Time: How Good are these Recipes?\n",
    "\n",
    "**Name(s)**: Tauhid Noor\n",
    "\n",
    "**Website Link**: https://taunoor.github.io/Classification-model-for-recipes/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "\n",
    "##### Model type:\n",
    "In this report, I will create a prediction model that tries to predict the rating - response variable - of recipes based on other given information in the dataset. I will be building a multiclass classification model to predict the ratings since the ratings are discrete values (1-5). I chose ratings as my response variable over other metrics because it's reasonable to see ratings as the dependent variable, and features such as calories, no. of ingredients, macronutrients, etc as independent variables that determine the quality/enjoyability of a recipe. Moreover, since I'm building a classification model that deals with discrete values, ratings is the only usable metric that suits the description of a discrete variable. The other variables would be more appropriate for a regression model since they are continuous variables. \n",
    "\n",
    "##### Variables:\n",
    "For my classification model, with `rating` column as my response variable, I will be using `calories`,`n_ingredients`, `minutes`, `total fats`, `carbohydrates`, `protein`, `sugar` columns as my features (tentative). The transformations of the features will be decided on as we look to see what improves the model's performance level. I chose these metrics because I think these metrics would assess the healthiness, taste, convenience, and nourishment of the recipe which would determine if the user enjoyed the food and rated it high. \n",
    "\n",
    "##### Evaluation method:\n",
    "I will be evaluating the model by using the **mean accuracy**, that is, finding the proportion of labels that the model got right. For a classfication model, I think determining the proportion of correctly predicted values is a more appropriate method than the common **RMSE** and **R^2** methods because the latter two are suited to regression models that deal with continuous values. I also decided against using **Precision** or **Recall** because while they may be for classification models, they are specifically meant for binary-based classification models. Moreover, for the discrete values (1-5), I want all the predictions to be weighed equally, in other words, there is no value from range 1-5 that is more important to accurately predict than the other. They are all equally important. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.652554Z",
     "start_time": "2019-10-31T23:36:27.180520Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import ast\n",
    "from scipy import stats\n",
    "\n",
    "import plotly.express as px\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "\n",
    "from sklearn.preprocessing import Binarizer, FunctionTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Framing the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for the data cleaning process was taken from Project 3 which dealt with the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.657068Z",
     "start_time": "2019-10-31T23:36:28.654650Z"
    }
   },
   "outputs": [],
   "source": [
    "#read in the datasets in csv form\n",
    "interactions_df = pd.read_csv('RAW_interactions.csv')\n",
    "recipes_df = pd.read_csv('RAW_recipes.csv')\n",
    "\n",
    "#merge the two dataframes using the recipe id as a way to align the data\n",
    "df = interactions_df.merge(recipes_df,left_on='recipe_id',right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_mean = df.groupby('recipe_id').mean()['rating'] #group the df by different recipes and and average their ratings\n",
    "rating_mean = rating_mean.reset_index() #this is for merging\n",
    "rating_mean = rating_mean.rename(columns={\"rating\":'avg_rating'})#rename the column \n",
    "df = df.merge(rating_mean,left_on='recipe_id',right_on='recipe_id') #df with the average rating series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['id']) #dropped the id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_to_lst = df['nutrition'].apply(lambda x: ast.literal_eval(x)) #convert the string list to an actual list\n",
    "df['nutrition'] = str_to_lst \n",
    "\n",
    "df['calories'] = df['nutrition'].apply(lambda x: x[0]) #separating the one column of lists into several ones w/ values\n",
    "df['total fat'] = df['nutrition'].apply(lambda x: x[1])\n",
    "df['sugar'] = df['nutrition'].apply(lambda x: x[2])\n",
    "df['sodium'] = df['nutrition'].apply(lambda x: x[3])\n",
    "df['protein'] = df['nutrition'].apply(lambda x: x[4])\n",
    "df['saturated fat'] = df['nutrition'].apply(lambda x: x[5])\n",
    "df['carbohydrates'] = df['nutrition'].apply(lambda x: x[6])\n",
    "df = df.drop(columns=['nutrition'])\n",
    "#df.head(5) #display the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_days = df['submitted'].apply(lambda x: pd.to_datetime('2023-05-12') - pd.to_datetime(x))\n",
    "n_years = n_days.apply(lambda x: int(str(x).split(' ')[0])/365)\n",
    "df['recipe age'] = n_years\n",
    "\n",
    "n_days = df['date'].apply(lambda x: pd.to_datetime('2023-05-12') - pd.to_datetime(x))\n",
    "n_years = n_days.apply(lambda x: int(str(x).split(' ')[0])/365)\n",
    "df['interaction age'] = n_years\n",
    "\n",
    "df = df.drop(columns=['date','submitted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'recipe_id', 'rating', 'review', 'name', 'minutes',\n",
       "       'contributor_id', 'tags', 'n_steps', 'steps', 'description',\n",
       "       'ingredients', 'n_ingredients', 'avg_rating', 'calories', 'total fat',\n",
       "       'sugar', 'sodium', 'protein', 'saturated fat', 'carbohydrates',\n",
       "       'recipe age', 'interaction age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns #make rating response. Initial 2 features: calories, n_ingredients. \n",
    "#Next 2 features(transformed): fat+protein+carb, mins/n_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the initial model, I will use Decision Tree Classification Model since it predicts discrete values like the `rating` column. I will choose `sugar`, `calories`, and `n_ingredients` as the features. All 3 columns are quantitative. I will leave the `sugar` column as itself. I transformed the `calories` column into **natural log** values so that the unusually large values and outliers don't distort the results of the prediction model. I transformed the `n_ingredients` to a **binary** format (1 and 0) to indicate high number of ingredients **(1)** and low number of ingredients **(0)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r3/mc3pdgtj3rn3d0pd71phd8540000gr/T/ipykernel_9817/3975100523.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['calories'] = final_df['calories'].replace(0,0.01) #to avoid log error\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>sugar</th>\n",
       "      <th>calories</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>total fat</th>\n",
       "      <th>protein</th>\n",
       "      <th>minutes</th>\n",
       "      <th>carbohydrates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>95.3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>143.5</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>182.4</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>182.4</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>151.0</td>\n",
       "      <td>658.2</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>45.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>40</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  sugar  calories  n_ingredients  n_steps  total fat  protein  \\\n",
       "0       5   50.0      95.3              8        4        1.0      5.0   \n",
       "1       5   25.0     143.5             10        9        5.0     10.0   \n",
       "2       5   50.0     182.4             14       14        2.0     11.0   \n",
       "3       5   50.0     182.4             14       14        2.0     11.0   \n",
       "4       4  151.0     658.2             12        7       45.0     24.0   \n",
       "\n",
       "   minutes  carbohydrates  \n",
       "0       40            7.0  \n",
       "1       30            7.0  \n",
       "2       22           13.0  \n",
       "3       22           13.0  \n",
       "4       40           29.0  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = df[df['rating']!=0] #remove the ratings of 0 since those correspond to missing ratings\n",
    "final_df['calories'] = final_df['calories'].replace(0,0.01) #to avoid log error\n",
    "final_df = final_df[['rating','sugar','calories','n_ingredients',\\\n",
    "                     'n_steps','total fat','protein','minutes','carbohydrates']] #pick out the columns\n",
    "final_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the X and y (response variables) and split the data into train and test sets\n",
    "X = final_df.drop('rating',axis=1)\n",
    "y = final_df['rating']\n",
    "\n",
    "train_X,test_X,train_y,test_y = train_test_split(X,y,test_size=0.25,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy of the Baseline Model is: 0.774052398402888\n"
     ]
    }
   ],
   "source": [
    "#define the transformers for the columns\n",
    "def passthrough(data):\n",
    "    return data[['sugar']]\n",
    "\n",
    "preproc = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('Calories',FunctionTransformer(np.log),['calories']),\n",
    "        ('num_ingredients', Binarizer(threshold=8), ['n_ingredients']),\n",
    "        ('sugar',FunctionTransformer(passthrough),['sugar'])\n",
    "    ],\n",
    "    remainder='drop') #drop the rest of the columns\n",
    "\n",
    "pl = Pipeline([('preprocessor',preproc),('DTC',DecisionTreeClassifier(max_depth=6))]) #arbitrary max_depth value\n",
    "pl.fit(train_X,train_y)\n",
    "pl.predict(test_X)\n",
    "print('The mean accuracy of the Baseline Model is:',(pl.predict(test_X)==test_y).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of our baseline model can be considered sufficient. The accuracy of our model is approximately 77.405% which leaves room for improvement, but since it's our baseline model, to be able to accurately label more often than not in our initial model, it can be considered promising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our final model, I will engineer two new additional features with several columns: `total fat`, `protein`, and `carbohydrate` columns for one feature, and `minutes` and `n_steps` for the other. I will also test out the best hyperparameters: I will choose the best performing classification model between Decision Tree Classifier and Random Forest Classifier. I will decide by comparing the training accuracy and testing accuracy of the two different models. The error values will be the mean accuracy of our predictions for each max depth for the respective model. After picking out the highest average of the training and test error from each model, I will then cross-compare between the two models to see which is the highest between the two. \n",
    "\n",
    "It's important to pick the best sub-hyperparameter (max_depth) to avoid overfitting or underfitting, and then the best hyperparameter (decision tree/random forest) to get the best overall performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [],
   "source": [
    "#two new features \n",
    "def macronutrients(data):\n",
    "    return pd.DataFrame(data['total fat'] + data['protein'] + data['carbohydrates'])\n",
    "\n",
    "def effort(data):\n",
    "    return pd.DataFrame(data['minutes']/data['n_steps'])\n",
    "\n",
    "imp_preproc = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('Calories',FunctionTransformer(np.log),['calories']),\n",
    "        ('num_ingredients', Binarizer(threshold=8), ['n_ingredients']),\n",
    "        ('macronutrients', FunctionTransformer(macronutrients),['total fat','protein','carbohydrates']),\n",
    "        ('effort',FunctionTransformer(effort),['minutes','n_steps'])\n",
    "    ],\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.773088</td>\n",
       "      <td>0.774289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.773088</td>\n",
       "      <td>0.774289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.773088</td>\n",
       "      <td>0.774289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.773100</td>\n",
       "      <td>0.774216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.773137</td>\n",
       "      <td>0.774308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.773173</td>\n",
       "      <td>0.774362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.773319</td>\n",
       "      <td>0.773979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.773702</td>\n",
       "      <td>0.773670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.774237</td>\n",
       "      <td>0.772977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.775009</td>\n",
       "      <td>0.772339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.776169</td>\n",
       "      <td>0.771208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.777561</td>\n",
       "      <td>0.770260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.779178</td>\n",
       "      <td>0.769330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.781323</td>\n",
       "      <td>0.766924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.783997</td>\n",
       "      <td>0.764426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  train_accuracy  test_accuracy\n",
       "0           1        0.773088       0.774289\n",
       "1           2        0.773088       0.774289\n",
       "2           3        0.773088       0.774289\n",
       "3           4        0.773100       0.774216\n",
       "4           5        0.773137       0.774308\n",
       "5           6        0.773173       0.774362\n",
       "6           7        0.773319       0.773979\n",
       "7           8        0.773702       0.773670\n",
       "8           9        0.774237       0.772977\n",
       "9          10        0.775009       0.772339\n",
       "10         11        0.776169       0.771208\n",
       "11         12        0.777561       0.770260\n",
       "12         13        0.779178       0.769330\n",
       "13         14        0.781323       0.766924\n",
       "14         15        0.783997       0.764426"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dataframe of training and test accuracy for decision tree\n",
    "dict_val = {'max_depth':[],'train_accuracy':[],'test_accuracy':[]}\n",
    "\n",
    "for i in range(1,16):\n",
    "    pl = Pipeline([('Preprocessor',imp_preproc),('DTC',DecisionTreeClassifier(max_depth=i))])\n",
    "    pl.fit(train_X,train_y)\n",
    "    dict_val['max_depth'].append(i)\n",
    "    dict_val['train_accuracy'].append((pl.predict(train_X)==train_y).mean())\n",
    "    dict_val['test_accuracy'].append((pl.predict(test_X)==test_y).mean())\n",
    "    \n",
    "scores = pd.DataFrame(dict_val)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth         13.000000\n",
      "train_accuracy     0.779196\n",
      "test_accuracy      0.769367\n",
      "mean_average       0.774281\n",
      "mean_accuracy      0.774281\n",
      "Name: 12, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#calculating the average of the two mean accuracies, to find the best max depth value\n",
    "scores['mean_accuracy']=(scores[['train_accuracy','test_accuracy']].sum(axis=1)/2)\n",
    "best_mean_ind = scores['mean_accuracy'].idxmax()\n",
    "print(scores.loc[best_mean_ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After going through an iterative process to find the mean accuracies of the different max depths of our Decision Tree, we found the best max_depth to be 13, and the average of the training and testing accuracies to be approximately 77.428%. We will now do the same with the Random Forest Classifier algorithm and compare the two different models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.773088</td>\n",
       "      <td>0.774289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.773088</td>\n",
       "      <td>0.774289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.773088</td>\n",
       "      <td>0.774289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.773088</td>\n",
       "      <td>0.774289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.773088</td>\n",
       "      <td>0.774289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.773088</td>\n",
       "      <td>0.774289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.773088</td>\n",
       "      <td>0.774289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.773088</td>\n",
       "      <td>0.774289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.773094</td>\n",
       "      <td>0.774289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.773131</td>\n",
       "      <td>0.774235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.773228</td>\n",
       "      <td>0.774253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.773355</td>\n",
       "      <td>0.774271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.773750</td>\n",
       "      <td>0.774162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.774504</td>\n",
       "      <td>0.773998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.775853</td>\n",
       "      <td>0.773761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  train_accuracy  test_accuracy\n",
       "0           1        0.773088       0.774289\n",
       "1           2        0.773088       0.774289\n",
       "2           3        0.773088       0.774289\n",
       "3           4        0.773088       0.774289\n",
       "4           5        0.773088       0.774289\n",
       "5           6        0.773088       0.774289\n",
       "6           7        0.773088       0.774289\n",
       "7           8        0.773088       0.774289\n",
       "8           9        0.773094       0.774289\n",
       "9          10        0.773131       0.774235\n",
       "10         11        0.773228       0.774253\n",
       "11         12        0.773355       0.774271\n",
       "12         13        0.773750       0.774162\n",
       "13         14        0.774504       0.773998\n",
       "14         15        0.775853       0.773761"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_val2 = {'max_depth':[],'train_accuracy':[],'test_accuracy':[]}\n",
    "\n",
    "for j in range(1,16):\n",
    "    pl2 = RandomForestClassifier(max_depth=j)\n",
    "    pl2.fit(train_X,train_y)\n",
    "    dict_val2['max_depth'].append(j)\n",
    "    dict_val2['train_accuracy'].append((pl2.predict(train_X)==train_y).mean())\n",
    "    dict_val2['test_accuracy'].append((pl2.predict(test_X)==test_y).mean())\n",
    "    \n",
    "scores2 = pd.DataFrame(dict_val2)\n",
    "scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth         15.000000\n",
      "train_accuracy     0.775951\n",
      "test_accuracy      0.773688\n",
      "mean_accuracy      0.774819\n",
      "Name: 14, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "scores2['mean_accuracy']=(scores2[['train_accuracy','test_accuracy']].sum(axis=1)/2)\n",
    "best_mean_ind = scores2['mean_accuracy'].idxmax()\n",
    "print(scores2.loc[best_mean_ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After going through an iterative process to find the mean accuracies of the different max depths of our Random Forest, we found the best max depth to be 15, and the average of the training and testing accuracies to be approximately 77.482%. \n",
    "\n",
    "If we compare the two models, the Random Forest model has marginally better accuracy across the the training and testing accuracies than that of the Decision Tree model. The Random Forest model is \"better\" by 0.54%. While the difference may be small, objectively the Random Forest model should be the final model for its performance. \n",
    "\n",
    "The final model is an improvement over the baseline model. Its mean accuracy is better by 0.77%. The improvement is marginal but after adding two new reasonable features, and finding the best hyperparameters through an iterative process, it is the best we can do.\n",
    "\n",
    "The improvement that we observed can be attributed to the new features. The first new feature will add all the values of the macronutrients (fat, protein, and carbohydrates) of a recipe because it is reasonable to assume that the higher your total PDV of fat, protein and carbohydrate, the more nourishing the recipe is, which should cause users to rate the recipe higher. The second feature divides the number of minutes to make the recipe by the number of steps. This transformation tells us the average time spent on one step of the recipe, which shows the amount of detail and care is given to prepare the recipe. The more care the recipe is prepared with, the better it will come out. Hence, we should expect users to rate it higher. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.666489Z",
     "start_time": "2019-10-31T23:36:28.664381Z"
    }
   },
   "source": [
    "After coming up with the final model, it's important to check if the model is biased in some way. I will check to see if there is a substantial difference in performance level of the model when feeding it data separated into two groups. I will use a **permutation test** to find the significance of our findings.\n",
    "\n",
    "**Group 1:** The dataset with high number of ingredients (greater than 8)\n",
    "\n",
    "**Group 2:** The dataset with low number of ingredients (less than or equal to 8)\n",
    "\n",
    "\n",
    "**Null hypothesis:** The model is fair. There is no difference in mean accuracy between data with low no. of ingredients and high no. of ingredients.\n",
    "\n",
    "**Alternative hypothesis:** The model is not fair. There is a difference in mean accuracy betwene data with low no. of ingredients and high no. of ingredients. \n",
    "\n",
    "**Evaluation metric:** Mean accuracy\n",
    "\n",
    "**Test statistic:** Absolute difference in mean accuracy\n",
    "\n",
    "**Significance level:** 1%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=15)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_pl = RandomForestClassifier(max_depth=15)\n",
    "main_pl.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick the difference in mean accuracy as test statistic\n",
    "#do a permutation test where you shuffle the high and low no. of ing\n",
    "#separate the data into two groups\n",
    "grouped_df = test_X.copy()\n",
    "\n",
    "grouped_df['Group']=test_X['n_ingredients'].apply(lambda x: 1 if x>8 else 0)\n",
    "grouped_df['y'] = test_y\n",
    "\n",
    "#finding the observed statistic\n",
    "one = grouped_df[grouped_df['Group']==1]\n",
    "ind_vals = one.drop(columns=['Group','y'],axis=1)\n",
    "response_val = one['y']\n",
    "\n",
    "zero = grouped_df[grouped_df['Group']==0]\n",
    "ind_vals2 = zero.drop(columns=['Group','y'],axis=1)\n",
    "response_val2 = zero['y']\n",
    "\n",
    "one_score = (main_pl.predict(ind_vals)==response_val).mean()\n",
    "zero_score = (main_pl.predict(ind_vals2)==response_val2).mean()\n",
    "\n",
    "obs = abs(one_score-zero_score)\n",
    "\n",
    "sim_lst = []\n",
    "for i in range(500):\n",
    "    grouped_df['Group'] = np.random.permutation(grouped_df['Group'])\n",
    "    \n",
    "    one = grouped_df[grouped_df['Group']==1]\n",
    "    ind_vals = one.drop(columns=['Group','y'],axis=1)\n",
    "    response_val = one['y']\n",
    "\n",
    "    zero = grouped_df[grouped_df['Group']==0]\n",
    "    ind_vals2 = zero.drop(columns=['Group','y'],axis=1)\n",
    "    response_val2 = zero['y']\n",
    "    \n",
    "    sim_one_score = (main_pl.predict(ind_vals)==response_val).mean()\n",
    "    sim_zero_score = (main_pl.predict(ind_vals2)==response_val2).mean()\n",
    "    \n",
    "    sim = abs(sim_one_score-sim_zero_score)\n",
    "    \n",
    "    sim_lst.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "histnorm": "probability",
         "hovertemplate": "0=%{x}<br>probability=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "nbinsx": 75,
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          0.006137326398748644,
          0.0026245642274386194,
          0.0032817060244026974,
          0.002559554393055441,
          0.0018944066752564215,
          0.0014563121439470361,
          0.0003690817365086252,
          0.0003690817365086252,
          0.003143680434801399,
          0.0014643180647820886,
          0.005618210191386086,
          0.001602343654383498,
          0.00510709990485847,
          0.0020404381856928833,
          0.0029246331691465954,
          0.00773566709271456,
          0.0010182176126376508,
          0.0029246331691465954,
          0.0007261545917647272,
          0.0016103495752185504,
          0.0035817749661106735,
          0.004457964028729444,
          0.0004340915708918036,
          0.0007991703469829581,
          0.0013832963887288052,
          0.002259485451347576,
          0.0056262161122210275,
          0.005553200357002908,
          0.0027055859034919028,
          0.002770595737875081,
          0.004742021128767204,
          0.006429389419621567,
          0.000872186102201189,
          0.0013182865543456268,
          0.005188121580911642,
          0.0003610758156735727,
          0.0004420974917269671,
          0.0002230502260721634,
          0.0017483751648199597,
          6.901279480064915e-05,
          0.006137326398748644,
          0.00328971194523775,
          0.0017483751648199597,
          0.0027055859034919028,
          0.0020404381856928833,
          0.0016103495752185504,
          0.006867483950930953,
          0.0033547217796209283,
          0.0010912333678558817,
          0.0014643180647820886,
          0.0002880600604553418,
          0.0011642491230741125,
          0.00021504430523711093,
          0.0002230502260721634,
          0.002770595737875081,
          0.0012372648782923434,
          0.0013102806335104633,
          0.0017483751648199597,
          0.002843611493093312,
          0.0007991703469829581,
          0.007589635582278098,
          0.0036547907213290154,
          0.00416590100785641,
          0.0001500344708539325,
          0.002332501206565696,
          0.004230910842239588,
          0.005326147170513051,
          0.0008071762678180106,
          0.0020404381856928833,
          0.003800822231765366,
          0.0016753594096017288,
          0.0014563121439470361,
          0.001829396840873243,
          0.0017483751648199597,
          0.005326147170513051,
          0.0022674913721825174,
          0.0028516174139284756,
          0.0003610758156735727,
          0.000515113246945087,
          0.0002960659812905053,
          0.0011642491230741125,
          0.002332501206565696,
          0.004449958107894392,
          0.005472178680949624,
          0.0008801920230362414,
          0.0002960659812905053,
          0.004969074315256949,
          0.007443604071841636,
          0.003216696190019519,
          0.0014643180647820886,
          0.0018944066752564215,
          0.0027786016587101336,
          0.003362727700455981,
          0.0028516174139284756,
          0.002559554393055441,
          0.0013182865543456268,
          0.004969074315256949,
          0.0013182865543456268,
          0.00766265133749644,
          0.0014563121439470361,
          0.008108751789640767,
          0.0007261545917647272,
          0.0002230502260721634,
          0.0024785327170021576,
          0.0017483751648199597,
          0.004011863576585006,
          0.0035087592108924426,
          0.0033547217796209283,
          0.004888052639203666,
          0.0027786016587101336,
          0.0002880600604553418,
          0.0032817060244026974,
          0.006494399254004746,
          0.0048960585600388296,
          0.0014563121439470361,
          4.0029604174707245e-06,
          0.00693249378531402,
          0.001829396840873243,
          0.0009452018574194199,
          0.0007341605125997797,
          0.004961068394422008,
          7.701871563581264e-05,
          0.008100745868805714,
          0.0066404307644412075,
          0.0014563121439470361,
          0.0013832963887288052,
          0.007305578482240338,
          0.0016753594096017288,
          0.005326147170513051,
          0.004384948273511213,
          0.0005071073261100345,
          0.0013913023095638577,
          0.0009452018574194199,
          0.001172255043909165,
          0.0009532077782544723,
          0.000872186102201189,
          0.0030626587587481158,
          0.0004340915708918036,
          6.901279480064915e-05,
          0.0017563810856549011,
          0.004449958107894392,
          0.0013102806335104633,
          0.0004420974917269671,
          0.0009532077782544723,
          0.0019674224304745414,
          4.0029604174707245e-06,
          0.004011863576585006,
          0.0059832889674771295,
          0.0038658320661485446,
          0.0007261545917647272,
          0.0013102806335104633,
          0.005480184601784566,
          0.0005071073261100345,
          0.00605630472269536,
          0.0017563810856549011,
          0.0023405071274008593,
          0.0033547217796209283,
          0.0032086902691845776,
          0.002843611493093312,
          0.0007341605125997797,
          0.004311932518292871,
          0.006575420930058029,
          0.0037278064765471353,
          0.0010992392886910451,
          0.00430392659745793,
          0.0011642491230741125,
          0.001975428351309705,
          0.005691225946604206,
          0.004961068394422008,
          0.0013832963887288052,
          0.0034357434556742117,
          0.007305578482240338,
          0.0016833653304367813,
          0.0002230502260721634,
          0.0002230502260721634,
          0.006786462274877558,
          0.003800822231765366,
          0.0024055169617840377,
          0.004522973863112512,
          0.00014202855001899106,
          0.0005881290021634289,
          0.0037278064765471353,
          0.0037928163109303137,
          0.0013102806335104633,
          0.0019674224304745414,
          0.00021504430523711093,
          0.004742021128767204,
          0.006867483950930953,
          0.0004340915708918036,
          0.004011863576585006,
          0.002632570148273783,
          0.008619862076168383,
          0.00409288525263829,
          0.00518011566007659,
          0.005188121580911642,
          0.0013913023095638577,
          0.0028516174139284756,
          0.0026245642274386194,
          0.001529327899165267,
          0.0013832963887288052,
          0.0026975799826569613,
          0.004750027049602368,
          0.00584526337787572,
          0.005326147170513051,
          0.004969074315256949,
          0.0037928163109303137,
          0.0017483751648199597,
          0.007589635582278098,
          0.002843611493093312,
          0.0004340915708918036,
          0.002113453940911003,
          0.005991294888312182,
          0.005115105825693411,
          4.0029604174707245e-06,
          0.003646784800493852,
          0.00409288525263829,
          0.0032086902691845776,
          0.0005881290021634289,
          0.001245270799127396,
          0.002770595737875081,
          0.003362727700455981,
          0.0037928163109303137,
          0.0013913023095638577,
          0.001902412596091474,
          0.0014563121439470361,
          0.0014563121439470361,
          0.006275351988350053,
          0.004019869497420059,
          0.0034277375348391592,
          0.0028516174139284756,
          0.0026975799826569613,
          0.001902412596091474,
          0.0032817060244026974,
          0.001602343654383498,
          0.0008071762678180106,
          0.0034357434556742117,
          0.0012372648782923434,
          0.002186469696129345,
          0.004823042804820488,
          0.008181767544858998,
          0.006348367743568284,
          0.002632570148273783,
          0.0010912333678558817,
          0.005991294888312182,
          0.004084879331803237,
          0.0004420974917269671,
          0.0009452018574194199,
          0.0037278064765471353,
          0.0025515484722204995,
          0.0004340915708918036,
          0.00409288525263829,
          0.00518011566007659,
          0.0039388478213667755,
          0.004823042804820488,
          0.005699231867439258,
          0.0002880600604553418,
          0.0007261545917647272,
          0.002486538637837321,
          0.0002960659812905053,
          0.0002230502260721634,
          0.0011642491230741125,
          7.701871563581264e-05,
          0.0042389167630747515,
          0.0013102806335104633,
          0.0002880600604553418,
          0.001902412596091474,
          0.0002880600604553418,
          0.0014643180647820886,
          0.0008801920230362414,
          0.0014563121439470361,
          0.001172255043909165,
          0.0020404381856928833,
          0.0006611447573815488,
          0.0011642491230741125,
          0.0017563810856549011,
          0.0031356745139662356,
          0.0026245642274386194,
          0.006502405174839798,
          0.001602343654383498,
          0.0013832963887288052,
          0.0034277375348391592,
          0.001245270799127396,
          0.006064310643530524,
          0.004457964028729444,
          0.010445255956624044,
          0.0004340915708918036,
          0.004823042804820488,
          0.004677011294384026,
          0.0011642491230741125,
          0.003573769045275621,
          0.001975428351309705,
          0.001245270799127396,
          0.0068594780300959,
          0.003873837986983597,
          0.0020404381856928833,
          0.001529327899165267,
          0.007808682847932791,
          0.0004420974917269671,
          0.0010182176126376508,
          0.002632570148273783,
          0.00014202855001899106,
          0.005699231867439258,
          0.007224556806187055,
          0.005480184601784566,
          0.003143680434801399,
          0.004157895087021468,
          0.005399162925731282,
          0.0010912333678558817,
          0.004530979783947675,
          0.002332501206565696,
          0.005618210191386086,
          0.002486538637837321,
          0.0006611447573815488,
          0.0026245642274386194,
          0.0032817060244026974,
          0.0030706646795830572,
          7.701871563581264e-05,
          0.001602343654383498,
          0.0022674913721825174,
          0.0024055169617840377,
          0.0005801230813282654,
          0.0032817060244026974,
          0.0059832889674771295,
          0.006494399254004746,
          0.0029246331691465954,
          0.0020484441065279357,
          0.0016103495752185504,
          0.0007261545917647272,
          0.004969074315256949,
          0.0007341605125997797,
          0.0029246331691465954,
          0.0017483751648199597,
          0.0004340915708918036,
          0.0024785327170021576,
          7.701871563581264e-05,
          0.004603995539165906,
          0.004384948273511213,
          0.0024785327170021576,
          0.0003610758156735727,
          0.0001500344708539325,
          0.002989643003529774,
          0.0007261545917647272,
          0.0018944066752564215,
          0.0017563810856549011,
          0.004019869497420059,
          0.002770595737875081,
          0.0010182176126376508,
          0.0035817749661106735,
          0.005334153091348104,
          0.0018944066752564215,
          0.0026975799826569613,
          0.0013182865543456268,
          0.0010912333678558817,
          0.004530979783947675,
          7.701871563581264e-05,
          0.005326147170513051,
          0.001602343654383498,
          0.001602343654383498,
          0.003946853742201828,
          0.0033547217796209283,
          0.0001500344708539325,
          0.0030706646795830572,
          0.0037278064765471353,
          0.0022674913721825174,
          0.0017483751648199597,
          0.0026245642274386194,
          0.00350075329005739,
          0.0013832963887288052,
          0.0016833653304367813,
          0.004742021128767204,
          0.001902412596091474,
          0.004677011294384026,
          0.008100745868805714,
          4.0029604174707245e-06,
          0.004603995539165906,
          0.00518011566007659,
          0.00350075329005739,
          0.0030626587587481158,
          0.004311932518292871,
          0.0016753594096017288,
          0.004157895087021468,
          0.0005801230813282654,
          0.0076706572583314925,
          0.002989643003529774,
          0.0029976489243649374,
          0.0029976489243649374,
          0.0014643180647820886,
          0.0036547907213290154,
          0.002332501206565696,
          0.001602343654383498,
          0.005764241701822437,
          4.0029604174707245e-06,
          0.0006611447573815488,
          0.0006611447573815488,
          0.0022674913721825174,
          0.004084879331803237,
          0.003216696190019519,
          0.001829396840873243,
          0.0002230502260721634,
          0.0045959896183308535,
          0.0023405071274008593,
          0.005764241701822437,
          0.0048960585600388296,
          0.007224556806187055,
          0.007086531216585645,
          0.000515113246945087,
          0.0035087592108924426,
          0.0030626587587481158,
          0.0005801230813282654,
          0.0009532077782544723,
          0.002989643003529774,
          0.0032817060244026974,
          0.0034357434556742117,
          0.004384948273511213,
          0.0023405071274008593,
          0.0006611447573815488,
          0.0009452018574194199,
          0.0034357434556742117,
          0.00430392659745793,
          0.003719800555712083,
          0.001829396840873243,
          0.0026245642274386194,
          0.0009452018574194199,
          0.005991294888312182,
          0.010510265791007223,
          0.008830903420988023,
          0.0016753594096017288,
          0.0002880600604553418,
          0.004677011294384026,
          0.0004340915708918036,
          0.002259485451347576,
          0.0010262235334727032,
          0.0004420974917269671,
          0.0068594780300959,
          0.001975428351309705,
          0.000515113246945087,
          0.0025515484722204995,
          0.0031356745139662356,
          0.0029976489243649374,
          0.00328971194523775,
          0.0009532077782544723,
          0.0025515484722204995,
          0.0002960659812905053,
          0.0059832889674771295,
          7.701871563581264e-05,
          0.0048960585600388296,
          0.001975428351309705,
          0.0008071762678180106,
          0.007589635582278098,
          0.0026975799826569613,
          0.002486538637837321,
          0.003719800555712083,
          0.003216696190019519,
          0.005188121580911642,
          0.0018213909200380796,
          0.0029976489243649374,
          0.0003690817365086252,
          0.0005801230813282654,
          0.0034277375348391592,
          0.0002960659812905053,
          0.0019674224304745414,
          0.0003610758156735727,
          0.0032086902691845776,
          0.004011863576585006,
          0.0025515484722204995,
          0.004011863576585006,
          0.0020484441065279357,
          0.0037278064765471353,
          0.0003690817365086252,
          0.007443604071841636,
          0.004230910842239588,
          0.0021214598617461666,
          0.0032086902691845776,
          4.0029604174707245e-06,
          4.0029604174707245e-06,
          0.003873837986983597,
          0.007159546971803876,
          0.00437694235267605,
          0.00416590100785641,
          0.004888052639203666,
          0.005407168846566446,
          0.006575420930058029,
          0.0018213909200380796,
          0.00518011566007659,
          0.0002960659812905053,
          0.005699231867439258,
          0.004815036883985546,
          0.0037278064765471353,
          0.004084879331803237,
          0.008100745868805714,
          0.0008071762678180106,
          0.0001500344708539325,
          0.004961068394422008,
          0.0021214598617461666,
          0.006494399254004746,
          0.00021504430523711093,
          0.0005801230813282654,
          0.005764241701822437,
          0.007232562727021996,
          0.00510709990485847
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "shapes": [
         {
          "line": {
           "color": "red"
          },
          "type": "line",
          "x0": 0.008473830565732032,
          "x1": 0.008473830565732032,
          "xref": "x",
          "y0": 0,
          "y1": 1,
          "yref": "y domain"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Empirical Distribution of the Absolute Mean Differences in Accuracy"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "range": [
          -0.02,
          0.02
         ],
         "title": {
          "text": "0"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "probability"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"4374eec9-be8d-4758-b935-84763e8a9474\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4374eec9-be8d-4758-b935-84763e8a9474\")) {                    Plotly.newPlot(                        \"4374eec9-be8d-4758-b935-84763e8a9474\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"histnorm\":\"probability\",\"hovertemplate\":\"0=%{x}<br>probability=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"nbinsx\":75,\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.006137326398748644,0.0026245642274386194,0.0032817060244026974,0.002559554393055441,0.0018944066752564215,0.0014563121439470361,0.0003690817365086252,0.0003690817365086252,0.003143680434801399,0.0014643180647820886,0.005618210191386086,0.001602343654383498,0.00510709990485847,0.0020404381856928833,0.0029246331691465954,0.00773566709271456,0.0010182176126376508,0.0029246331691465954,0.0007261545917647272,0.0016103495752185504,0.0035817749661106735,0.004457964028729444,0.0004340915708918036,0.0007991703469829581,0.0013832963887288052,0.002259485451347576,0.0056262161122210275,0.005553200357002908,0.0027055859034919028,0.002770595737875081,0.004742021128767204,0.006429389419621567,0.000872186102201189,0.0013182865543456268,0.005188121580911642,0.0003610758156735727,0.0004420974917269671,0.0002230502260721634,0.0017483751648199597,6.901279480064915e-05,0.006137326398748644,0.00328971194523775,0.0017483751648199597,0.0027055859034919028,0.0020404381856928833,0.0016103495752185504,0.006867483950930953,0.0033547217796209283,0.0010912333678558817,0.0014643180647820886,0.0002880600604553418,0.0011642491230741125,0.00021504430523711093,0.0002230502260721634,0.002770595737875081,0.0012372648782923434,0.0013102806335104633,0.0017483751648199597,0.002843611493093312,0.0007991703469829581,0.007589635582278098,0.0036547907213290154,0.00416590100785641,0.0001500344708539325,0.002332501206565696,0.004230910842239588,0.005326147170513051,0.0008071762678180106,0.0020404381856928833,0.003800822231765366,0.0016753594096017288,0.0014563121439470361,0.001829396840873243,0.0017483751648199597,0.005326147170513051,0.0022674913721825174,0.0028516174139284756,0.0003610758156735727,0.000515113246945087,0.0002960659812905053,0.0011642491230741125,0.002332501206565696,0.004449958107894392,0.005472178680949624,0.0008801920230362414,0.0002960659812905053,0.004969074315256949,0.007443604071841636,0.003216696190019519,0.0014643180647820886,0.0018944066752564215,0.0027786016587101336,0.003362727700455981,0.0028516174139284756,0.002559554393055441,0.0013182865543456268,0.004969074315256949,0.0013182865543456268,0.00766265133749644,0.0014563121439470361,0.008108751789640767,0.0007261545917647272,0.0002230502260721634,0.0024785327170021576,0.0017483751648199597,0.004011863576585006,0.0035087592108924426,0.0033547217796209283,0.004888052639203666,0.0027786016587101336,0.0002880600604553418,0.0032817060244026974,0.006494399254004746,0.0048960585600388296,0.0014563121439470361,4.0029604174707245e-06,0.00693249378531402,0.001829396840873243,0.0009452018574194199,0.0007341605125997797,0.004961068394422008,7.701871563581264e-05,0.008100745868805714,0.0066404307644412075,0.0014563121439470361,0.0013832963887288052,0.007305578482240338,0.0016753594096017288,0.005326147170513051,0.004384948273511213,0.0005071073261100345,0.0013913023095638577,0.0009452018574194199,0.001172255043909165,0.0009532077782544723,0.000872186102201189,0.0030626587587481158,0.0004340915708918036,6.901279480064915e-05,0.0017563810856549011,0.004449958107894392,0.0013102806335104633,0.0004420974917269671,0.0009532077782544723,0.0019674224304745414,4.0029604174707245e-06,0.004011863576585006,0.0059832889674771295,0.0038658320661485446,0.0007261545917647272,0.0013102806335104633,0.005480184601784566,0.0005071073261100345,0.00605630472269536,0.0017563810856549011,0.0023405071274008593,0.0033547217796209283,0.0032086902691845776,0.002843611493093312,0.0007341605125997797,0.004311932518292871,0.006575420930058029,0.0037278064765471353,0.0010992392886910451,0.00430392659745793,0.0011642491230741125,0.001975428351309705,0.005691225946604206,0.004961068394422008,0.0013832963887288052,0.0034357434556742117,0.007305578482240338,0.0016833653304367813,0.0002230502260721634,0.0002230502260721634,0.006786462274877558,0.003800822231765366,0.0024055169617840377,0.004522973863112512,0.00014202855001899106,0.0005881290021634289,0.0037278064765471353,0.0037928163109303137,0.0013102806335104633,0.0019674224304745414,0.00021504430523711093,0.004742021128767204,0.006867483950930953,0.0004340915708918036,0.004011863576585006,0.002632570148273783,0.008619862076168383,0.00409288525263829,0.00518011566007659,0.005188121580911642,0.0013913023095638577,0.0028516174139284756,0.0026245642274386194,0.001529327899165267,0.0013832963887288052,0.0026975799826569613,0.004750027049602368,0.00584526337787572,0.005326147170513051,0.004969074315256949,0.0037928163109303137,0.0017483751648199597,0.007589635582278098,0.002843611493093312,0.0004340915708918036,0.002113453940911003,0.005991294888312182,0.005115105825693411,4.0029604174707245e-06,0.003646784800493852,0.00409288525263829,0.0032086902691845776,0.0005881290021634289,0.001245270799127396,0.002770595737875081,0.003362727700455981,0.0037928163109303137,0.0013913023095638577,0.001902412596091474,0.0014563121439470361,0.0014563121439470361,0.006275351988350053,0.004019869497420059,0.0034277375348391592,0.0028516174139284756,0.0026975799826569613,0.001902412596091474,0.0032817060244026974,0.001602343654383498,0.0008071762678180106,0.0034357434556742117,0.0012372648782923434,0.002186469696129345,0.004823042804820488,0.008181767544858998,0.006348367743568284,0.002632570148273783,0.0010912333678558817,0.005991294888312182,0.004084879331803237,0.0004420974917269671,0.0009452018574194199,0.0037278064765471353,0.0025515484722204995,0.0004340915708918036,0.00409288525263829,0.00518011566007659,0.0039388478213667755,0.004823042804820488,0.005699231867439258,0.0002880600604553418,0.0007261545917647272,0.002486538637837321,0.0002960659812905053,0.0002230502260721634,0.0011642491230741125,7.701871563581264e-05,0.0042389167630747515,0.0013102806335104633,0.0002880600604553418,0.001902412596091474,0.0002880600604553418,0.0014643180647820886,0.0008801920230362414,0.0014563121439470361,0.001172255043909165,0.0020404381856928833,0.0006611447573815488,0.0011642491230741125,0.0017563810856549011,0.0031356745139662356,0.0026245642274386194,0.006502405174839798,0.001602343654383498,0.0013832963887288052,0.0034277375348391592,0.001245270799127396,0.006064310643530524,0.004457964028729444,0.010445255956624044,0.0004340915708918036,0.004823042804820488,0.004677011294384026,0.0011642491230741125,0.003573769045275621,0.001975428351309705,0.001245270799127396,0.0068594780300959,0.003873837986983597,0.0020404381856928833,0.001529327899165267,0.007808682847932791,0.0004420974917269671,0.0010182176126376508,0.002632570148273783,0.00014202855001899106,0.005699231867439258,0.007224556806187055,0.005480184601784566,0.003143680434801399,0.004157895087021468,0.005399162925731282,0.0010912333678558817,0.004530979783947675,0.002332501206565696,0.005618210191386086,0.002486538637837321,0.0006611447573815488,0.0026245642274386194,0.0032817060244026974,0.0030706646795830572,7.701871563581264e-05,0.001602343654383498,0.0022674913721825174,0.0024055169617840377,0.0005801230813282654,0.0032817060244026974,0.0059832889674771295,0.006494399254004746,0.0029246331691465954,0.0020484441065279357,0.0016103495752185504,0.0007261545917647272,0.004969074315256949,0.0007341605125997797,0.0029246331691465954,0.0017483751648199597,0.0004340915708918036,0.0024785327170021576,7.701871563581264e-05,0.004603995539165906,0.004384948273511213,0.0024785327170021576,0.0003610758156735727,0.0001500344708539325,0.002989643003529774,0.0007261545917647272,0.0018944066752564215,0.0017563810856549011,0.004019869497420059,0.002770595737875081,0.0010182176126376508,0.0035817749661106735,0.005334153091348104,0.0018944066752564215,0.0026975799826569613,0.0013182865543456268,0.0010912333678558817,0.004530979783947675,7.701871563581264e-05,0.005326147170513051,0.001602343654383498,0.001602343654383498,0.003946853742201828,0.0033547217796209283,0.0001500344708539325,0.0030706646795830572,0.0037278064765471353,0.0022674913721825174,0.0017483751648199597,0.0026245642274386194,0.00350075329005739,0.0013832963887288052,0.0016833653304367813,0.004742021128767204,0.001902412596091474,0.004677011294384026,0.008100745868805714,4.0029604174707245e-06,0.004603995539165906,0.00518011566007659,0.00350075329005739,0.0030626587587481158,0.004311932518292871,0.0016753594096017288,0.004157895087021468,0.0005801230813282654,0.0076706572583314925,0.002989643003529774,0.0029976489243649374,0.0029976489243649374,0.0014643180647820886,0.0036547907213290154,0.002332501206565696,0.001602343654383498,0.005764241701822437,4.0029604174707245e-06,0.0006611447573815488,0.0006611447573815488,0.0022674913721825174,0.004084879331803237,0.003216696190019519,0.001829396840873243,0.0002230502260721634,0.0045959896183308535,0.0023405071274008593,0.005764241701822437,0.0048960585600388296,0.007224556806187055,0.007086531216585645,0.000515113246945087,0.0035087592108924426,0.0030626587587481158,0.0005801230813282654,0.0009532077782544723,0.002989643003529774,0.0032817060244026974,0.0034357434556742117,0.004384948273511213,0.0023405071274008593,0.0006611447573815488,0.0009452018574194199,0.0034357434556742117,0.00430392659745793,0.003719800555712083,0.001829396840873243,0.0026245642274386194,0.0009452018574194199,0.005991294888312182,0.010510265791007223,0.008830903420988023,0.0016753594096017288,0.0002880600604553418,0.004677011294384026,0.0004340915708918036,0.002259485451347576,0.0010262235334727032,0.0004420974917269671,0.0068594780300959,0.001975428351309705,0.000515113246945087,0.0025515484722204995,0.0031356745139662356,0.0029976489243649374,0.00328971194523775,0.0009532077782544723,0.0025515484722204995,0.0002960659812905053,0.0059832889674771295,7.701871563581264e-05,0.0048960585600388296,0.001975428351309705,0.0008071762678180106,0.007589635582278098,0.0026975799826569613,0.002486538637837321,0.003719800555712083,0.003216696190019519,0.005188121580911642,0.0018213909200380796,0.0029976489243649374,0.0003690817365086252,0.0005801230813282654,0.0034277375348391592,0.0002960659812905053,0.0019674224304745414,0.0003610758156735727,0.0032086902691845776,0.004011863576585006,0.0025515484722204995,0.004011863576585006,0.0020484441065279357,0.0037278064765471353,0.0003690817365086252,0.007443604071841636,0.004230910842239588,0.0021214598617461666,0.0032086902691845776,4.0029604174707245e-06,4.0029604174707245e-06,0.003873837986983597,0.007159546971803876,0.00437694235267605,0.00416590100785641,0.004888052639203666,0.005407168846566446,0.006575420930058029,0.0018213909200380796,0.00518011566007659,0.0002960659812905053,0.005699231867439258,0.004815036883985546,0.0037278064765471353,0.004084879331803237,0.008100745868805714,0.0008071762678180106,0.0001500344708539325,0.004961068394422008,0.0021214598617461666,0.006494399254004746,0.00021504430523711093,0.0005801230813282654,0.005764241701822437,0.007232562727021996,0.00510709990485847],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"0\"},\"range\":[-0.02,0.02]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"probability\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Empirical Distribution of the Absolute Mean Differences in Accuracy\"},\"barmode\":\"relative\",\"shapes\":[{\"line\":{\"color\":\"red\"},\"type\":\"line\",\"x0\":0.008473830565732032,\"x1\":0.008473830565732032,\"xref\":\"x\",\"y0\":0,\"y1\":1,\"yref\":\"y domain\"}]},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('4374eec9-be8d-4758-b935-84763e8a9474');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.histogram(pd.DataFrame(sim_lst), x=0, nbins=75, histnorm='probability', \n",
    "                   title='Empirical Distribution of the Absolute Mean Differences in Accuracy')\n",
    "fig.add_vline(x=obs, line_color='red')\n",
    "fig.update_layout(xaxis_range=[-0.02, 0.02])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html('histplot.html', include_plotlyjs='cdn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The p-value is: 0.008\n"
     ]
    }
   ],
   "source": [
    "print('The p-value is:',(np.array(sim_lst)>=obs).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is 0.8% which falls below the 1% threshold. Hence, we reject the null hypothesis which claimed there was no significant difference. Now while we may have rejected the null hypothesis, it doesn't mean we accept the alternative hypothesis. Based on our permutation test, we can only say that there is an association between the performance of the model and the group."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
